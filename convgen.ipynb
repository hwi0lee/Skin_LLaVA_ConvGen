{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hylee/miniconda3/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from openai import OpenAI, AzureOpenAI\n",
    "import json\n",
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    seed = 47\n",
    "    log = True\n",
    "    print = False\n",
    "    version = \"v.1.6\"\n",
    "    project_name = \"Skin_LLaVA_Convgen\"\n",
    "    model_name = \"gpt-4-1106-preview\"\n",
    "    num_test_samples = 10\n",
    "    num_example = 2\n",
    "    root_dir = \"/data2/ArtLab_LLM/label/train_231109/JPEGImages/\"\n",
    "    system_path = \"./prompt/system_message.txt\"\n",
    "    sample_1_path = f\"./prompt/sample_1_{version}.txt\"\n",
    "    sample_2_path = f\"./prompt/sample_2_{version}.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_query_imgdir(sample, root_dir):\n",
    "    with open(root_dir+sample, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    img_dir = root_dir+data[\"file_name\"]\n",
    "\n",
    "    keys_to_drop = [\"caption\", \"part\", \"file_name\", \"rosacea\", \"acne\", \"eczema\"]\n",
    "    for key in keys_to_drop:\n",
    "        data.pop(key, None)\n",
    "\n",
    "    data[\"dryness\"] = data.pop(\"hydration\", None)\n",
    "\n",
    "    return {\"query\":str(data), \"img_name\":img_dir}\n",
    "\n",
    "random.seed(CFG.seed)\n",
    "\n",
    "test_samples =  random.sample([f for f in os.listdir(CFG.root_dir) if f.endswith(\".json\")], CFG.num_test_samples)\n",
    "\n",
    "test_container = [generate_query_imgdir(sample, CFG.root_dir) for sample in test_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_conversation(system_message, samples, query, model_name):\n",
    "\n",
    "    azure = [\"gpt-35-turbo\", \"gpt-35-turbo-16k\", \"gpt-35-turbo-instruct\", \"gpt-4\", \"gpt-4-32k\", \"gpt-4-1106-preview\", \"gpt-4-vision-preview\"]\n",
    "    # public = [\"gpt-3.5-turbo-1106\", \"gpt-3.5-turbo\", \"gpt-3.5-turbo-16k\", \"gpt-3.5-turbo-instruct\", \"gpt-4\"]\n",
    "\n",
    "    if model_name in azure:\n",
    "        client = AzureOpenAI(\n",
    "            azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "            api_key = os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    "            api_version = \"2023-08-01-preview\"\n",
    "        )\n",
    "    # elif model_name in public:\n",
    "    #     client = OpenAI(\n",
    "    #         api_key = os.getenv(\"PUBLIC_OPENAI_KEY\"),\n",
    "    #     )\n",
    "    else:\n",
    "        raise ValueError(\"Model name is unrecognizable.\")\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message}\n",
    "    ]\n",
    "    for sample in samples:\n",
    "        messages.append({\"role\": \"user\", \"content\": sample['context']})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": sample['response']})\n",
    "    messages.append({\"role\": \"user\", \"content\": query})\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model = model_name,\n",
    "        messages = messages\n",
    "    )\n",
    "\n",
    "    content = response.choices[0].message.content\n",
    "    completion_tokens = response.usage.completion_tokens\n",
    "    prompt_tokens = response.usage.prompt_tokens\n",
    "\n",
    "    if model_name in [\"gpt-35-turbo\", \"gpt-3.5-turbo-1106\", \"gpt-35-turbo\", \"gpt-35-turbo-instruct\"]:\n",
    "        coef = (0.000002,0.0000015) #completion, prompt\n",
    "    elif model_name in [\"gpt-4\"]:\n",
    "        coef = (0.00006,0.00003)\n",
    "    elif model_name in [\"gpt-4-1106-preview\", \"gpt-4-vision-preview\"]:\n",
    "        coef = (0.00003,0.00001)\n",
    "    elif model_name in [\"gpt-4-32k\", \"gpt-4-32k\"]:\n",
    "        coef = (0.00012, 0.00006)\n",
    "    elif model_name in [\"gpt-35-turbo-16k\", \"gpt-3.5-turbo-16k\"]:\n",
    "        coef = (0.000004, 0.000003)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model name\")\n",
    "    \n",
    "    price = completion_tokens*coef[0] + prompt_tokens*coef[1]\n",
    "\n",
    "    return content, price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_container = []\n",
    "\n",
    "with open(CFG.system_path, 'r') as file:\n",
    "    system_message = file.read()\n",
    "if CFG.num_example >= 1:\n",
    "    with open(CFG.sample_1_path, 'r') as file:\n",
    "        sample_1 = file.read()\n",
    "        file_container.append(sample_1)\n",
    "if CFG.num_example == 2:\n",
    "    with open(CFG.sample_2_path, 'r') as file:\n",
    "        sample_2 = file.read()\n",
    "        file_container.append(sample_2)\n",
    "\n",
    "def preprocess_example(file):\n",
    "    context = file.split(\"\\n\")[0]\n",
    "    response = file[len(context):].strip()\n",
    "    return {\"context\": context, \"response\": response}\n",
    "\n",
    "fewshot_samples = [preprocess_example(file) for file in file_container]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m2gnldud\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nas/home/hylee/project/convgen/wandb/run-20231130_125900-w7zfhtmr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/2gnldud/Skin_LLaVA_ConvGen/runs/w7zfhtmr' target=\"_blank\">gpt-4-1106-preview 1-shot v.1.6</a></strong> to <a href='https://wandb.ai/2gnldud/Skin_LLaVA_ConvGen' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/2gnldud/Skin_LLaVA_ConvGen' target=\"_blank\">https://wandb.ai/2gnldud/Skin_LLaVA_ConvGen</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/2gnldud/Skin_LLaVA_ConvGen/runs/w7zfhtmr' target=\"_blank\">https://wandb.ai/2gnldud/Skin_LLaVA_ConvGen/runs/w7zfhtmr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [09:27<00:00, 56.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price: $ 0.24738000000000004\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "from PIL import Image\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "if CFG.log:\n",
    "    wandb.init(project=CFG.project_name, group=CFG.model_name + \" \" + CFG.version + \" s.\" + str(CFG.seed), name=CFG.model_name + \" \" + str(CFG.num_example) + \"-shot \" + CFG.version)\n",
    "    table = wandb.Table(columns=['Image Name', 'Image', 'Query', 'Generated Conversation'])\n",
    "\n",
    "sum = 0\n",
    "\n",
    "for test_sample in tqdm(test_container):\n",
    "    conv_generated, price = generate_conversation(system_message, fewshot_samples, test_sample['query'], CFG.model_name)\n",
    "    sum += price\n",
    "    sample_image = Image.open(test_sample['img_name'])\n",
    "    img_name = os.path.basename(test_sample['img_name'])\n",
    "\n",
    "    if CFG.log:\n",
    "        table.add_data(img_name, wandb.Image(sample_image), test_sample['query'], conv_generated)\n",
    "        \n",
    "    if CFG.print:\n",
    "        print(os.path.basename(test_sample['img_name']))\n",
    "        sample_image.show()\n",
    "        print(test_sample['query'])\n",
    "        print(conv_generated + \"\\n\\n\")\n",
    "\n",
    "if CFG.log:\n",
    "    wandb.log({\"Log\": table})\n",
    "    \n",
    "    artifact = wandb.Artifact(\"prompts\", type=\"dataset\")\n",
    "    artifact.add_file(CFG.system_path, \"system_message.txt\")\n",
    "    if CFG.num_example > 0:\n",
    "        artifact.add_file(CFG.sample_1_path, \"sample_1.txt\")\n",
    "        if CFG.num_example > 1:\n",
    "            artifact.add_file(CFG.sample_2_path, \"sample_2.txt\")\n",
    "    wandb.log_artifact(artifact)\n",
    "\n",
    "print(\"Price: $\", sum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
